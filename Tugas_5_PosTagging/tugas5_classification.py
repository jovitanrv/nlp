# -*- coding: utf-8 -*-
"""Tugas5_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vq60KXwiOW1vNYqZgl9cf6jiiPr82sqT
"""

import nltk
nltk.download('punkt')

from sklearn import tree
from sklearn.feature_extraction import DictVectorizer
from sklearn.pipeline import Pipeline
import pandas as pd

"""Baca data latih, split antara kata dan tag."""

df = pd.read_csv("train.01.tsv",sep="\t", header=None)

word_train = []
tag_train = []
tags = []
words = []
i = 0

for index, row in df.iterrows():
    word = row[0].lower()
    tag = row[1]
    if i < 50:
      if word != 'nan':
        words.append(word)
        tags.append(tag)
        if word == '.':
          word_train.append(words)
          tag_train.append(tags)
          words = []
          tags = []

    if word == '.':
      i += 1
      if (i == 50):
        break

word_train

tag_train

"""Fungsi untuk ekstraksi fitur."""

def features(sentence, index):
    """ sentence: [w1, w2, ...], index: the index of the word """
    # print("sentence index = ")
    # print(sentence[index])
    prefix_1 = ''
    prefix_2 = ''
    suffix_1 = ''
    suffix_2 = ''
    if (len(sentence[index])>2):
      prefix_1 = sentence[index][0]
      prefix_2 = sentence[index][:2]
      suffix_1 = sentence[index][-1]
      suffix_2 = sentence[index][-2:]
    return {
        'word': sentence[index],
        'prefix-1': prefix_1,
        'prefix-2': prefix_2,        
        'suffix-1': suffix_1,
        'suffix-2': suffix_2,        
        'prev_word': '' if index == 0 else sentence[index - 1],
        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],
    }

"""Tes ekstraksi fitur dari sebuah kalimat."""

# sent_example = 'Situasi yang kini kita alami'
sent_example_tokens = word_train

for i in range (0,len(sent_example_tokens)):
  print('fitur kata ',sent_example_tokens[i],'adalah sebagai berikut:')
  token_feature = features(sent_example_tokens,i)
  print(token_feature)

"""Fungsi untuk transformasi format dataset."""

def transform_to_dataset(sentences, tags):
    X, y = [], []
 
    for sentence_idx in range(len(sentences)):
        for index in range(len(sentences[sentence_idx])):
            X.append(features(sentences[sentence_idx], index))
            y.append(tags[sentence_idx][index])
 
    return X, y

"""Input data uji."""

dt = pd.read_csv("test_sentences.tsv",sep="\t", header=None)
dt = dt.astype(str)

words, tags = [] , [] 
word_test, tag_test = [] , []

for index, row in dt.iterrows():   
    wordd = row[0].lower()
    tagg = row[1]
    if wordd != 'nan':
        words.append(wordd)
        tags.append(tagg)
        if wordd == '.' :
            word_test.append(words)
            tag_test.append(tags)
            words = []
            tags = []

word_test

tag_test

"""**Training**"""

X, y = transform_to_dataset(word_train, tag_train)


from sklearn import tree
from sklearn.feature_extraction import DictVectorizer
from sklearn.pipeline import Pipeline
 
clf = Pipeline([
    ('vectorizer', DictVectorizer(sparse=False)),
    ('classifier', tree.DecisionTreeClassifier(criterion='entropy'))
])
clf.fit(X, y)   
 
print('Training completed')

"""**Testing**"""

X_test, y_test = transform_to_dataset(word_test, tag_test)

akurasi = clf.score(X_test, y_test)
print("Nilai akurasi classification : ",round(akurasi,4))

X_test[0],

i = 0
for i in range(0,len(X_test)):
  print("Hasil tagging : ",X_test[i],"\n" "tag : ",y_test[i])
  i += 1