# -*- coding: utf-8 -*-
"""Tugas4_NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jYtdTjRuyXyf8ZKkUHrDn9mGS0g4L0__

Import library.
"""

from glob import glob
import logging
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)
from gensim import utils
import gensim.models
from sklearn.decomposition import IncrementalPCA    
from sklearn.manifold import TSNE                   
import numpy as np

"""Menggabungkan 20 files menjadi satu."""

files = glob('*.txt')  # list of all .txt files in the directory

with open('artikel.txt', 'w') as f:
    for file in files:
        with open(file) as infile:
            f.write(infile.read()+'\n')

from gensim.test.utils import datapath
from gensim import utils

class MyCorpus(object): 
    """An interator that yields sentences (lists of str)."""

    def __iter__(self):
        corpus_path = '/content/artikel.txt'
        for line in open(corpus_path):
            # assume there's one document per line, tokens separated by whitespace
            # asumsi 1 dokumen adalah 1 kalimat, dituliskan per baris. Antar token dipisahkan dengan spasi
            yield utils.simple_preprocess(line)

sentences = MyCorpus()
model1 = gensim.models.Word2Vec(sentences=sentences, size=100,min_count=1)
model5 = gensim.models.Word2Vec(sentences=sentences, size=100,min_count=5)

"""**Nomor 1**"""

#min_count = 1
vec_positif1 = model1.wv['ekonomi']
print(vec_positif1)

#min_count = 5
vec_positif5 = model5.wv['ekonomi']
print(vec_positif5)

"""**Nomor 2**

min_count = 1
"""

#Similarity > 0,5
print(model1.wv.similarity('kebijakan', 'ekonomi'))

# 0 < Similarity < 0,5
print(model1.wv.similarity('keuangan', 'dipertimbangkan'))

# -1 < Similarity < -0,5
print(model1.wv.similarity('kompetisi', 'berkala'))

"""min_count = 5"""

#Similarity > 0,5
print(model5.wv.similarity('uang', 'tunai'))

# 0 < Similarity < 0,5
print(model5.wv.similarity('peringatan', 'ramadhan'))

# -1 < Similarity < -0,5
print(model1.wv.similarity('asuransi', 'kotor'))

"""**Nomor 3**

min_count = 1
"""

print(model1.wv.most_similar(positive=['ekonomi'], topn=5))

"""min_count = 5"""

print(model5.wv.most_similar(positive=['ekonomi'], topn=5))

"""**Nomor 4**"""

def reduce_dimensions(model):
    num_dimensions = 2  # final num dimensions (2D, 3D, etc)

    vectors = [] # positions in vector space
    labels = [] # keep track of words to label our data again later
    for word in model.wv.vocab:
        vectors.append(model.wv[word])
        labels.append(word)

    # convert both lists into numpy vectors for reduction
    vectors = np.asarray(vectors)
    labels = np.asarray(labels)

    # reduce using t-SNE
    vectors = np.asarray(vectors)
    tsne = TSNE(n_components=num_dimensions, random_state=0)
    vectors = tsne.fit_transform(vectors)

    x_vals = [v[0] for v in vectors]
    y_vals = [v[1] for v in vectors]
    return x_vals, y_vals, labels

x_vals1, y_vals1, labels1 = reduce_dimensions(model1)
x_vals5, y_vals5, labels5 = reduce_dimensions(model5)

def plot_with_matplotlib(x_vals, y_vals, labels):
    import matplotlib.pyplot as plt
    import random

    random.seed(0)

    plt.figure(figsize=(12, 12))
    plt.scatter(x_vals, y_vals)

    #
    # Label randomly subsampled 25 data points
    #
    indices = list(range(len(labels)))
    selected_indices = random.sample(indices, 25)
    for i in selected_indices:
        plt.annotate(labels[i], (x_vals[i], y_vals[i]))

plot_with_matplotlib(x_vals1, y_vals1, labels1)