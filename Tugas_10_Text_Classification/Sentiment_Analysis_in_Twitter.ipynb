{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Sentiment Analysis in Twitter.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2OESy4IWQoM"
      },
      "source": [
        "# Sentiment analysis in Twitter\n",
        "\n",
        "**Reference:**\n",
        "http://www.sentiment140.com/\n",
        "\n",
        "\n",
        "**The algorithms:**\n",
        "1.   Linear Regression\n",
        "2.   Logistic Regression\n",
        "3.   Random Forest Classifier\n",
        "4.   Linear SVM\n",
        "5.   Multinomial NB\n",
        "\n",
        "**Dataset:** \n",
        "sentiment140.csv (Ref: sentiment140.com).\n",
        "\n",
        "The dataset contains 499.031 tweets, '0' represents negative sentiment and '1' represents positive sentiment\n",
        "\n",
        "Labelling process: Assume that any tweet with positive emoticons are positive, and tweets with negative emoticons are negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upVzK26QWQrA"
      },
      "source": [
        "# **Training Step**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGijVKUAovSI"
      },
      "source": [
        "### Read the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDV3B7l4WQrB",
        "outputId": "5961f5be-280b-4428-fc46-7c940c00efb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/sentiment140.csv\", nrows=30000)\n",
        "df.head()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@kconsidder You never tweet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Sick today  coding from the couch.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>@ChargerJenn Thx for answering so quick,I was afraid I was gonna crash twitter with all the spamming I did 2 RR..sorry bout that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Wii fit says I've lost 10 pounds since last time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@MrKinetik Not a thing!!!  I don't really have a life.....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   polarity                                                                                                                               text\n",
              "0         0                                                                                                      @kconsidder You never tweet  \n",
              "1         0                                                                                                 Sick today  coding from the couch.\n",
              "2         1  @ChargerJenn Thx for answering so quick,I was afraid I was gonna crash twitter with all the spamming I did 2 RR..sorry bout that \n",
              "3         1                                                                                Wii fit says I've lost 10 pounds since last time   \n",
              "4         0                                                                         @MrKinetik Not a thing!!!  I don't really have a life....."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o2bzNm0WQrX"
      },
      "source": [
        "The columns:\n",
        "\n",
        "*   `polarity` column is whether the tweet is s positive or not.\n",
        "*   `text` column is the text of the tweet..\n",
        "\n",
        "\n",
        "How many rows?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od6kaWswWQrY",
        "outputId": "3232d532-78cf-4936-e036-19137a972bde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIfKjv4sWQru"
      },
      "source": [
        "How many **positive** and **negative** tweets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csktyEZBWQrw",
        "outputId": "c019445d-b594-41f3-a159-8c50ed7c827f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.polarity.value_counts()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    15064\n",
              "0    14936\n",
              "Name: polarity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H38c6muWQsK"
      },
      "source": [
        "## Train the algorithms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x-9dpkkWQsM"
      },
      "source": [
        "### Vectorize the tweets\n",
        "\n",
        "Create a `TfidfVectorizer` and use it to vectorize the tweets. \n",
        "Use `max_features` to take a selection of terms (1000) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnIKKpTUWQsQ"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OjSw95DWQsl",
        "outputId": "58327043-db5b-48e2-97a0-d1aa5242249e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "vectors = vectorizer.fit_transform(df.text)\n",
        "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
        "words_df.head()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>15</th>\n",
              "      <th>1st</th>\n",
              "      <th>20</th>\n",
              "      <th>2day</th>\n",
              "      <th>2nd</th>\n",
              "      <th>30</th>\n",
              "      <th>able</th>\n",
              "      <th>about</th>\n",
              "      <th>account</th>\n",
              "      <th>actually</th>\n",
              "      <th>add</th>\n",
              "      <th>after</th>\n",
              "      <th>afternoon</th>\n",
              "      <th>again</th>\n",
              "      <th>ago</th>\n",
              "      <th>agree</th>\n",
              "      <th>ah</th>\n",
              "      <th>ahh</th>\n",
              "      <th>ahhh</th>\n",
              "      <th>air</th>\n",
              "      <th>album</th>\n",
              "      <th>all</th>\n",
              "      <th>almost</th>\n",
              "      <th>alone</th>\n",
              "      <th>already</th>\n",
              "      <th>alright</th>\n",
              "      <th>also</th>\n",
              "      <th>although</th>\n",
              "      <th>always</th>\n",
              "      <th>am</th>\n",
              "      <th>amazing</th>\n",
              "      <th>amp</th>\n",
              "      <th>an</th>\n",
              "      <th>and</th>\n",
              "      <th>annoying</th>\n",
              "      <th>another</th>\n",
              "      <th>...</th>\n",
              "      <th>work</th>\n",
              "      <th>worked</th>\n",
              "      <th>working</th>\n",
              "      <th>works</th>\n",
              "      <th>world</th>\n",
              "      <th>worried</th>\n",
              "      <th>worry</th>\n",
              "      <th>worse</th>\n",
              "      <th>worst</th>\n",
              "      <th>worth</th>\n",
              "      <th>would</th>\n",
              "      <th>wouldn</th>\n",
              "      <th>wow</th>\n",
              "      <th>write</th>\n",
              "      <th>writing</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wtf</th>\n",
              "      <th>www</th>\n",
              "      <th>xd</th>\n",
              "      <th>xoxo</th>\n",
              "      <th>xx</th>\n",
              "      <th>xxx</th>\n",
              "      <th>ya</th>\n",
              "      <th>yay</th>\n",
              "      <th>yea</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "      <th>yep</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yet</th>\n",
              "      <th>yo</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "      <th>youtube</th>\n",
              "      <th>yum</th>\n",
              "      <th>yup</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.334095</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.22101</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.427465</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         10  100   11   12   15  1st  ...  young  your  yourself  youtube  yum  yup\n",
              "0  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
              "1  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
              "2  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
              "3  0.427465  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
              "4  0.000000  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
              "\n",
              "[5 rows x 1000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaNSaJXxWQs5"
      },
      "source": [
        "### Setting the variables\n",
        "\n",
        "There are two variables: `X` and `y`.\n",
        "\n",
        "`X` = **features**\n",
        "\n",
        "`y` = **labels**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXsi0nWKWQs5"
      },
      "source": [
        "X = words_df\n",
        "y = df.polarity"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvcDvK5QWQtG"
      },
      "source": [
        "# **The algorithms:**\n",
        "\n",
        "1.   Linear Regression\n",
        "2.   Logistic Regression\n",
        "3.   Random Forest Classifier\n",
        "4.   Linear SVM\n",
        "5.   Multinomial NB\n",
        "\n",
        "\n",
        "**You can pick just ONE or ALL OF THEM.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcK7bVXJWQtH"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuFTkYb7WQtI"
      },
      "source": [
        "# **Training the algorithms**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0x0SOncjm9c"
      },
      "source": [
        "**Logistic Regression**\n",
        "\n",
        "- C: float, default = 1.0\n",
        "  - Inverse of regularization strength; must be a positive float. \n",
        "  - Smaller values specify stronger regularization.\n",
        "\n",
        "- solver = {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default = ’lbfgs’\n",
        "  - Algorithm to use in the optimization problem.\n",
        "  - For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
        "  - For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
        "  - ‘newton-cg’, ‘lbfgs’, ‘sag’ and ‘saga’ handle L2 or no penalty\n",
        "  - ‘liblinear’ and ‘saga’ also handle L1 penalty\n",
        "  - ‘saga’ also supports ‘elasticnet’ penalty\n",
        "  - ‘liblinear’ does not support setting penalty='none'\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOFHx7DOWQtI",
        "outputId": "5f3e43b2-06ce-4998-ad25-9c76c5847b9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "# Create and train a logistic regression\n",
        "logreg = LogisticRegression(C=1e9, solver='lbfgs', max_iter=1000)\n",
        "logreg.fit(X, y)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 14.9 s, sys: 865 ms, total: 15.8 s\n",
            "Wall time: 8.07 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL9Opu-Bkw4T"
      },
      "source": [
        "**Random Forest Classifier**\n",
        "\n",
        "- n_estimators: int, default = 100\n",
        "  - The number of trees in the forest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3g02RfpWQtL",
        "outputId": "2830575b-41c7-459a-87fd-4ed92eb41e79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "# Create and train a random forest classifier\n",
        "forest = RandomForestClassifier(n_estimators=50)\n",
        "forest.fit(X, y)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 29.3 s, sys: 34.8 ms, total: 29.4 s\n",
            "Wall time: 29.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FVZPKn2laZz"
      },
      "source": [
        "**Linear SVC**\n",
        "\n",
        "LinearSVC is another (faster) implementation of **Support Vector Classification** for the case of a **linear kernel**. \n",
        "\n",
        "Note that **LinearSVC** does not accept parameter kernel, as this is assumed to be linear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whua8HQaWQtO",
        "outputId": "25788cdb-0d94-412b-8772-b10cca7c1fb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "# Create and train a linear support vector classifier (LinearSVC)\n",
        "svc = LinearSVC()\n",
        "svc.fit(X, y)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 378 ms, sys: 5.99 ms, total: 384 ms\n",
            "Wall time: 386 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB-WsNhNmauu"
      },
      "source": [
        "**Multinomial NB**\n",
        "\n",
        "MultinomialNB implements the **naive Bayes algorithm** for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification (*where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cFI7uI8WQtR",
        "outputId": "47c8aa07-f1c8-4bd0-dc59-8bdb72deffd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "# Create and train a multinomial naive bayes classifier (MultinomialNB)\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(X, y)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 218 ms, sys: 4.93 ms, total: 223 ms\n",
            "Wall time: 150 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0dC4OBuWQtS"
      },
      "source": [
        "# Discussion 1\n",
        "\n",
        "How much faster were an algorithm compared to others?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3bIGp45WQtT"
      },
      "source": [
        "## Use the models\n",
        "\n",
        "We will use the model to predict whether the tweet is positive or negative.\n",
        "\n",
        "### Testing Data\n",
        "\n",
        "**You can add the testing data below.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5eTOxO5WQtU",
        "outputId": "d935b733-f314-4b9c-b60b-8e4f258c3c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "# Create some test data\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "\n",
        "datatest = pd.DataFrame({'content': [\n",
        "    \"I love the food\",\n",
        "    \"I hate hate hate hate this game\",\n",
        "    \"I'm not sure the taste of eggs\",\n",
        "    \"Did you see the news yesterday?\",\n",
        "    \"He is upset that he can't update his apps\",\n",
        "    \"The package was delivered late and the contents were broken\",\n",
        "    \"The wifi getting worst\",\n",
        "    \"I watch the video from my phone\",\n",
        "    \"I'm fine with this food\",\n",
        "    \"not good\",\n",
        "]})\n",
        "datatest"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love the food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I hate hate hate hate this game</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'm not sure the taste of eggs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Did you see the news yesterday?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>He is upset that he can't update his apps</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The package was delivered late and the contents were broken</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The wifi getting worst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I watch the video from my phone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I'm fine with this food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>not good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       content\n",
              "0                                              I love the food\n",
              "1                              I hate hate hate hate this game\n",
              "2                               I'm not sure the taste of eggs\n",
              "3                              Did you see the news yesterday?\n",
              "4                    He is upset that he can't update his apps\n",
              "5  The package was delivered late and the contents were broken\n",
              "6                                       The wifi getting worst\n",
              "7                              I watch the video from my phone\n",
              "8                                      I'm fine with this food\n",
              "9                                                     not good"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5RjU_IHWQtX"
      },
      "source": [
        "\n",
        "\n",
        "First we need to **vectorizer** the sentences into numbers, so the algorithm can understand them.\n",
        "\n",
        "Our algorithm only knows **certain words.** \n",
        "Run `vectorizer.get_feature_names()` to show you the list of the words it knows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3_hqSV2WQtY",
        "outputId": "66a08497-91dd-43c8-eec0-11d3d37f5e72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['10', '100', '11', '12', '15', '1st', '20', '2day', '2nd', '30', 'able', 'about', 'account', 'actually', 'add', 'after', 'afternoon', 'again', 'ago', 'agree', 'ah', 'ahh', 'ahhh', 'air', 'album', 'all', 'almost', 'alone', 'already', 'alright', 'also', 'although', 'always', 'am', 'amazing', 'amp', 'an', 'and', 'annoying', 'another', 'any', 'anymore', 'anyone', 'anything', 'anyway', 'app', 'apparently', 'apple', 'appreciate', 'are', 'around', 'art', 'as', 'ask', 'asleep', 'ass', 'at', 'ate', 'aw', 'awake', 'awards', 'away', 'awesome', 'aww', 'awww', 'baby', 'back', 'bad', 'band', 'bbq', 'bday', 'be', 'beach', 'beautiful', 'because', 'bed', 'been', 'beer', 'before', 'behind', 'being', 'believe', 'best', 'bet', 'better', 'big', 'bike', 'birthday', 'bit', 'bitch', 'black', 'blip', 'blog', 'blue', 'body', 'boo', 'book', 'books', 'bored', 'boring', 'both', 'bought', 'bout', 'box', 'boy', 'boys', 'break', 'breakfast', 'bring', 'bro', 'broke', 'broken', 'brother', 'brothers', 'btw', 'bus', 'business', 'busy', 'but', 'buy', 'by', 'bye', 'cake', 'call', 'called', 'came', 'can', 'cannot', 'cant', 'car', 'card', 'care', 'case', 'cat', 'catch', 'cause', 'cd', 'chance', 'change', 'channel', 'chat', 'check', 'chicken', 'chocolate', 'church', 'city', 'class', 'clean', 'cleaning', 'close', 'closed', 'club', 'coffee', 'cold', 'college', 'com', 'come', 'comes', 'coming', 'completely', 'computer', 'concert', 'congrats', 'cool', 'cos', 'could', 'couldn', 'country', 'couple', 'course', 'crap', 'crazy', 'cream', 'cry', 'crying', 'cut', 'cute', 'cuz', 'da', 'dad', 'damn', 'dance', 'date', 'daughter', 'david', 'day', 'days', 'ddlovato', 'de', 'dead', 'dear', 'decided', 'definitely', 'did', 'didn', 'didnt', 'die', 'died', 'dinner', 'dm', 'do', 'does', 'doesn', 'doesnt', 'dog', 'doing', 'don', 'done', 'dont', 'down', 'download', 'dream', 'dreams', 'dress', 'drink', 'drinking', 'drive', 'driving', 'drunk', 'dude', 'due', 'during', 'each', 'earlier', 'early', 'easy', 'eat', 'eating', 'either', 'else', 'em', 'email', 'end', 'ended', 'english', 'enjoy', 'enjoyed', 'enjoying', 'enough', 'episode', 'especially', 'even', 'evening', 'ever', 'every', 'everybody', 'everyone', 'everything', 'exactly', 'exam', 'exams', 'except', 'excited', 'exciting', 'eye', 'eyes', 'face', 'facebook', 'fact', 'fail', 'fair', 'fall', 'family', 'fan', 'fans', 'far', 'fast', 'favorite', 'fb', 'feel', 'feeling', 'feels', 'feet', 'fell', 'felt', 'few', 'ff', 'figure', 'final', 'finally', 'finals', 'find', 'fine', 'fingers', 'finish', 'finished', 'fire', 'first', 'fix', 'flight', 'flu', 'fly', 'fm', 'follow', 'followers', 'followfriday', 'following', 'food', 'for', 'forever', 'forget', 'forgot', 'forward', 'found', 'free', 'friday', 'friend', 'friends', 'from', 'front', 'fuck', 'fucking', 'full', 'fun', 'funny', 'game', 'games', 'garden', 'gave', 'gd', 'get', 'gets', 'getting', 'girl', 'girls', 'give', 'glad', 'go', 'god', 'goes', 'goin', 'going', 'gone', 'gonna', 'good', 'goodbye', 'goodnight', 'google', 'got', 'gotta', 'graduation', 'great', 'green', 'gt', 'guess', 'guitar', 'guy', 'guys', 'gym', 'ha', 'had', 'haha', 'hahaha', 'hair', 'half', 'hand', 'hang', 'happen', 'happened', 'happens', 'happy', 'hard', 'has', 'hate', 'hates', 'have', 'haven', 'havent', 'having', 'he', 'head', 'headache', 'headed', 'heading', 'hear', 'heard', 'heart', 'hehe', 'hell', 'hello', 'help', 'her', 'here', 'hey', 'hi', 'high', 'him', 'his', 'history', 'hit', 'hmm', 'holiday', 'home', 'homework', 'hope', 'hopefully', 'hoping', 'horrible', 'hot', 'hotel', 'hour', 'hours', 'house', 'how', 'http', 'hubby', 'hug', 'huge', 'hugs', 'hun', 'hungry', 'hurt', 'hurts', 'ice', 'idea', 'idk', 'if', 'ill', 'im', 'in', 'inside', 'instead', 'interesting', 'internet', 'into', 'iphone', 'ipod', 'is', 'isn', 'isnt', 'it', 'its', 'ive', 'jealous', 'job', 'join', 'jonas', 'jonasbrothers', 'july', 'june', 'jus', 'just', 'keep', 'keeps', 'kid', 'kids', 'kill', 'kind', 'kinda', 'knew', 'know', 'knows', 'la', 'lady', 'lakers', 'lame', 'laptop', 'last', 'late', 'later', 'laugh', 'lazy', 'learn', 'learning', 'least', 'leave', 'leaving', 'left', 'less', 'let', 'lets', 'life', 'like', 'liked', 'lil', 'line', 'link', 'list', 'listen', 'listening', 'little', 'live', 'living', 'll', 'lmao', 'lol', 'london', 'lonely', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'lost', 'lot', 'lots', 'love', 'loved', 'lovely', 'loves', 'loving', 'lt', 'luck', 'lucky', 'lunch', 'luv', 'ly', 'ma', 'mac', 'mad', 'made', 'mail', 'major', 'make', 'makes', 'making', 'man', 'many', 'maths', 'matter', 'may', 'maybe', 'mcfly', 'me', 'mean', 'means', 'meant', 'meet', 'meeting', 'message', 'met', 'might', 'miley', 'mileycyrus', 'mind', 'mine', 'minute', 'minutes', 'miss', 'missed', 'missing', 'mom', 'moment', 'monday', 'money', 'month', 'months', 'mood', 'moon', 'more', 'morning', 'most', 'mother', 'mouth', 'move', 'movie', 'movies', 'moving', 'mr', 'mtv', 'much', 'mum', 'music', 'must', 'my', 'myloc', 'myself', 'myspace', 'name', 'nap', 'near', 'need', 'needed', 'needs', 'never', 'new', 'news', 'next', 'nice', 'night', 'nights', 'nite', 'no', 'nope', 'not', 'nothing', 'now', 'number', 'of', 'off', 'office', 'oh', 'ohh', 'ok', 'okay', 'old', 'omg', 'on', 'once', 'one', 'ones', 'online', 'only', 'open', 'or', 'other', 'ouch', 'our', 'out', 'outside', 'over', 'own', 'packing', 'page', 'pain', 'paper', 'parents', 'park', 'part', 'party', 'pass', 'past', 'pay', 'peace', 'people', 'perfect', 'person', 'phone', 'photo', 'photos', 'pic', 'pick', 'pics', 'picture', 'pictures', 'pink', 'pizza', 'place', 'plan', 'plans', 'play', 'played', 'playing', 'please', 'pls', 'plurk', 'plus', 'point', 'pool', 'poor', 'post', 'posted', 'power', 'ppl', 'pretty', 'probably', 'problem', 'profile', 'project', 'proud', 'put', 'quite', 'quot', 'radio', 'rain', 'raining', 'rainy', 'random', 'rather', 're', 'read', 'reading', 'ready', 'real', 'realized', 'really', 'reason', 'red', 'relaxing', 'remember', 'reply', 'rest', 'revision', 'ride', 'right', 'rip', 'road', 'rock', 'room', 'run', 'running', 'sad', 'sadly', 'safe', 'said', 'same', 'sat', 'saturday', 'save', 'saw', 'say', 'saying', 'says', 'scared', 'scary', 'school', 'season', 'second', 'see', 'seeing', 'seem', 'seems', 'seen', 'send', 'sent', 'seriously', 'set', 'shall', 'shame', 'share', 'she', 'shirt', 'shit', 'shoes', 'shop', 'shopping', 'short', 'should', 'show', 'shower', 'shows', 'sick', 'side', 'sigh', 'sign', 'silly', 'sims', 'since', 'singing', 'sister', 'site', 'sitting', 'sleep', 'sleeping', 'sleepy', 'slept', 'slow', 'small', 'smile', 'so', 'some', 'someone', 'something', 'sometimes', 'son', 'song', 'songs', 'soo', 'soon', 'sooo', 'soooo', 'sore', 'sorry', 'sound', 'sounds', 'special', 'spend', 'spending', 'spent', 'star', 'start', 'started', 'starting', 'starts', 'stay', 'still', 'stomach', 'stop', 'store', 'story', 'straight', 'stuck', 'study', 'studying', 'stuff', 'stupid', 'such', 'suck', 'sucks', 'summer', 'sun', 'sunday', 'sunny', 'sunshine', 'super', 'support', 'supposed', 'sure', 'sweet', 'take', 'takes', 'taking', 'talk', 'talking', 'taylor', 'tea', 'team', 'tell', 'test', 'text', 'than', 'thank', 'thanks', 'that', 'thats', 'the', 'their', 'them', 'then', 'there', 'these', 'they', 'thing', 'things', 'think', 'thinking', 'thinks', 'this', 'tho', 'those', 'though', 'thought', 'three', 'throat', 'through', 'thru', 'thursday', 'thx', 'tickets', 'til', 'till', 'time', 'times', 'tinyurl', 'tired', 'to', 'today', 'together', 'told', 'tom', 'tommcfly', 'tomorrow', 'tonight', 'too', 'took', 'top', 'totally', 'tour', 'town', 'traffic', 'train', 'tried', 'trip', 'true', 'try', 'trying', 'tuesday', 'turn', 'tv', 'tweet', 'tweeting', 'tweets', 'twilight', 'twitpic', 'twitter', 'two', 'ugh', 'uk', 'under', 'understand', 'unfortunately', 'until', 'up', 'update', 'updates', 'upset', 'ur', 'us', 'use', 'used', 'using', 'vacation', 've', 'vegas', 'version', 'very', 'via', 'video', 'visit', 'voice', 'wait', 'waiting', 'wake', 'walk', 'wanna', 'want', 'wanted', 'wants', 'warm', 'was', 'wasn', 'watch', 'watched', 'watching', 'water', 'way', 'we', 'wear', 'weather', 'website', 'wedding', 'wednesday', 'week', 'weekend', 'weeks', 'weird', 'welcome', 'well', 'went', 'were', 'what', 'whats', 'when', 'where', 'which', 'while', 'white', 'who', 'whole', 'why', 'wife', 'will', 'win', 'wine', 'wish', 'wishes', 'wishing', 'wit', 'with', 'without', 'woke', 'won', 'wonder', 'wonderful', 'wondering', 'wont', 'woo', 'word', 'words', 'work', 'worked', 'working', 'works', 'world', 'worried', 'worry', 'worse', 'worst', 'worth', 'would', 'wouldn', 'wow', 'write', 'writing', 'wrong', 'wtf', 'www', 'xd', 'xoxo', 'xx', 'xxx', 'ya', 'yay', 'yea', 'yeah', 'year', 'years', 'yep', 'yes', 'yesterday', 'yet', 'yo', 'you', 'young', 'your', 'yourself', 'youtube', 'yum', 'yup']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpx_6TwXWQta"
      },
      "source": [
        "**Because we already have the list of words we know, we only want to count them.** So instead of `.fit_transform`, we just use `.transform`:\n",
        "\n",
        "```python\n",
        "datatest_vectors = vectorizer.transform(datatest.content)\n",
        "datatest_words_df = ......\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZo0qtPDWQta",
        "outputId": "27703af2-8733-4d9c-d180-b3bc9bcdeff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "# Put it through the vectoriser\n",
        "\n",
        "# transform, not fit_transform, because we already learned all our words\n",
        "datatest_vectors = vectorizer.transform(datatest.content)\n",
        "datatest_words_df = pd.DataFrame(datatest_vectors.toarray(), columns=vectorizer.get_feature_names())\n",
        "datatest_words_df.head()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>15</th>\n",
              "      <th>1st</th>\n",
              "      <th>20</th>\n",
              "      <th>2day</th>\n",
              "      <th>2nd</th>\n",
              "      <th>30</th>\n",
              "      <th>able</th>\n",
              "      <th>about</th>\n",
              "      <th>account</th>\n",
              "      <th>actually</th>\n",
              "      <th>add</th>\n",
              "      <th>after</th>\n",
              "      <th>afternoon</th>\n",
              "      <th>again</th>\n",
              "      <th>ago</th>\n",
              "      <th>agree</th>\n",
              "      <th>ah</th>\n",
              "      <th>ahh</th>\n",
              "      <th>ahhh</th>\n",
              "      <th>air</th>\n",
              "      <th>album</th>\n",
              "      <th>all</th>\n",
              "      <th>almost</th>\n",
              "      <th>alone</th>\n",
              "      <th>already</th>\n",
              "      <th>alright</th>\n",
              "      <th>also</th>\n",
              "      <th>although</th>\n",
              "      <th>always</th>\n",
              "      <th>am</th>\n",
              "      <th>amazing</th>\n",
              "      <th>amp</th>\n",
              "      <th>an</th>\n",
              "      <th>and</th>\n",
              "      <th>annoying</th>\n",
              "      <th>another</th>\n",
              "      <th>...</th>\n",
              "      <th>work</th>\n",
              "      <th>worked</th>\n",
              "      <th>working</th>\n",
              "      <th>works</th>\n",
              "      <th>world</th>\n",
              "      <th>worried</th>\n",
              "      <th>worry</th>\n",
              "      <th>worse</th>\n",
              "      <th>worst</th>\n",
              "      <th>worth</th>\n",
              "      <th>would</th>\n",
              "      <th>wouldn</th>\n",
              "      <th>wow</th>\n",
              "      <th>write</th>\n",
              "      <th>writing</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wtf</th>\n",
              "      <th>www</th>\n",
              "      <th>xd</th>\n",
              "      <th>xoxo</th>\n",
              "      <th>xx</th>\n",
              "      <th>xxx</th>\n",
              "      <th>ya</th>\n",
              "      <th>yay</th>\n",
              "      <th>yea</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "      <th>yep</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>yet</th>\n",
              "      <th>yo</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "      <th>youtube</th>\n",
              "      <th>yum</th>\n",
              "      <th>yup</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.521289</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.237644</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    10  100   11   12   15  1st  ...  young  your  yourself  youtube  yum  yup\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0       0.0      0.0  0.0  0.0\n",
              "\n",
              "[5 rows x 1000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrDQfcghWQtd"
      },
      "source": [
        "Confirm `datatest_words_df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYX_42wwWQtg",
        "outputId": "44298dcf-5bc7-415f-c22a-56adbc240626",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "datatest_words_df.shape"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpx_0hlcWQtv"
      },
      "source": [
        "# **Predicting the models**\n",
        "\n",
        "\n",
        "We use `.predict` to predict class labels for each sentence and it will give a `0` (*negative*) or a `1` (*positive*) class:\n",
        "\n",
        "```python\n",
        "datatest['pred_logreg'] = logreg.predict(datatest_words_df)\n",
        "```\n",
        "\n",
        "We use `.predict_proba` to estimate the probability of the prediction.\n",
        "\n",
        "The returned estimates for all classes are ordered by the label of classes:\n",
        "\n",
        "\n",
        "```python\n",
        "datatest['pred_logreg_prob'] = linreg.predict_proba(datatest_words_df)[:,1]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUJgJfQ_WQtw"
      },
      "source": [
        "# Predict using all our models. \n",
        "\n",
        "# Logistic Regression predictions + probabilities\n",
        "datatest['pred_logreg'] = logreg.predict(datatest_words_df)\n",
        "datatest['pred_logreg_proba'] = logreg.predict_proba(datatest_words_df)[:,1]\n",
        "\n",
        "# Random forest predictions + probabilities\n",
        "datatest['pred_forest'] = forest.predict(datatest_words_df)\n",
        "datatest['pred_forest_proba'] = forest.predict_proba(datatest_words_df)[:,1]\n",
        "\n",
        "# SVC predictions\n",
        "datatest['pred_svc'] = svc.predict(datatest_words_df)\n",
        "\n",
        "# Bayes predictions + probabilities\n",
        "datatest['pred_bayes'] = bayes.predict(datatest_words_df)\n",
        "datatest['pred_bayes_proba'] = bayes.predict_proba(datatest_words_df)[:,1]"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhERTSM_WQt9",
        "outputId": "029b75d8-ea96-446c-a86a-fa3330733283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        }
      },
      "source": [
        "datatest"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>pred_logreg</th>\n",
              "      <th>pred_logreg_proba</th>\n",
              "      <th>pred_forest</th>\n",
              "      <th>pred_forest_proba</th>\n",
              "      <th>pred_svc</th>\n",
              "      <th>pred_bayes</th>\n",
              "      <th>pred_bayes_proba</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love the food</td>\n",
              "      <td>1</td>\n",
              "      <td>0.868454</td>\n",
              "      <td>1</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.652036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I hate hate hate hate this game</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011870</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.131163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'm not sure the taste of eggs</td>\n",
              "      <td>0</td>\n",
              "      <td>0.368384</td>\n",
              "      <td>0</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.520409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Did you see the news yesterday?</td>\n",
              "      <td>1</td>\n",
              "      <td>0.528700</td>\n",
              "      <td>1</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.465336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>He is upset that he can't update his apps</td>\n",
              "      <td>0</td>\n",
              "      <td>0.154716</td>\n",
              "      <td>0</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.266105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The package was delivered late and the contents were broken</td>\n",
              "      <td>0</td>\n",
              "      <td>0.058225</td>\n",
              "      <td>0</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.219788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The wifi getting worst</td>\n",
              "      <td>0</td>\n",
              "      <td>0.021557</td>\n",
              "      <td>0</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.178278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I watch the video from my phone</td>\n",
              "      <td>1</td>\n",
              "      <td>0.519172</td>\n",
              "      <td>0</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.475156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I'm fine with this food</td>\n",
              "      <td>1</td>\n",
              "      <td>0.709365</td>\n",
              "      <td>1</td>\n",
              "      <td>0.826667</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.620767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>not good</td>\n",
              "      <td>0</td>\n",
              "      <td>0.478604</td>\n",
              "      <td>0</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.532576</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       content  ...  pred_bayes_proba\n",
              "0                                              I love the food  ...          0.652036\n",
              "1                              I hate hate hate hate this game  ...          0.131163\n",
              "2                               I'm not sure the taste of eggs  ...          0.520409\n",
              "3                              Did you see the news yesterday?  ...          0.465336\n",
              "4                    He is upset that he can't update his apps  ...          0.266105\n",
              "5  The package was delivered late and the contents were broken  ...          0.219788\n",
              "6                                       The wifi getting worst  ...          0.178278\n",
              "7                              I watch the video from my phone  ...          0.475156\n",
              "8                                      I'm fine with this food  ...          0.620767\n",
              "9                                                     not good  ...          0.532576\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUqM-23cWQuA"
      },
      "source": [
        "# Discussion 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIF17XNVWQuB"
      },
      "source": [
        "\n",
        "1.   What do the numbers mean? What's the difference between 0, 1, or 0,5?\n",
        "2.   Were there any sentences where the classifiers seemed to disagree about? Give your analysis!\n",
        "3.   What's the difference between using a (0 and 1) in sentiment analysis compared to a range of 0 - 1? When might you use one compared to another?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrmzLKXsWQuB"
      },
      "source": [
        "# **Testing our models**\n",
        "\n",
        "Which model performs the best??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VguiqYowWQuC",
        "outputId": "a4ce8fc4-b98d-4394-f0d0-e046efe10f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@kconsidder You never tweet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Sick today  coding from the couch.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>@ChargerJenn Thx for answering so quick,I was afraid I was gonna crash twitter with all the spamming I did 2 RR..sorry bout that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Wii fit says I've lost 10 pounds since last time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@MrKinetik Not a thing!!!  I don't really have a life.....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   polarity                                                                                                                               text\n",
              "0         0                                                                                                      @kconsidder You never tweet  \n",
              "1         0                                                                                                 Sick today  coding from the couch.\n",
              "2         1  @ChargerJenn Thx for answering so quick,I was afraid I was gonna crash twitter with all the spamming I did 2 RR..sorry bout that \n",
              "3         1                                                                                Wii fit says I've lost 10 pounds since last time   \n",
              "4         0                                                                         @MrKinetik Not a thing!!!  I don't really have a life....."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQFa5fS6WQuG"
      },
      "source": [
        "Our  dataframe is a list of many tweets. We turned this into `X` - vectorized words - and `y` - whether the tweet is negative or positive.\n",
        "\n",
        "Before we used `.fit(X, y)` to train on all of our data. \n",
        "\n",
        "Instead, **we can test our models** by doing a test/train split and see if the predictions match the actual labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZezgb-GWQuG"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3dbJS6uWQuI",
        "outputId": "781747b0-2137-4f11-90fc-da410a7cef5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "print(\"Training logistic regression\")\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training random forest\")\n",
        "forest.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training SVC\")\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training Naive Bayes\")\n",
        "bayes.fit(X_train, y_train)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training logistic regression\n",
            "Training random forest\n",
            "Training SVC\n",
            "Training Naive Bayes\n",
            "CPU times: user 40.3 s, sys: 853 ms, total: 41.2 s\n",
            "Wall time: 34.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fmBf0A3WQuJ"
      },
      "source": [
        "### Confusion matrices\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xreZ5f__WQuK"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0JryApBWQuN"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRSepgjzWQuN",
        "outputId": "1196c8c1-edf5-4e29-b649-64da70229164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = logreg.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>2751</td>\n",
              "      <td>993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>875</td>\n",
              "      <td>2881</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative                2751                 993\n",
              "Is positive                 875                2881"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fBpYencWQuO"
      },
      "source": [
        "#### Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df1s1LUYWQuP",
        "outputId": "716ed322-db21-4709-af67-b3c10da9a7b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = forest.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>2776</td>\n",
              "      <td>968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>1058</td>\n",
              "      <td>2698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative                2776                 968\n",
              "Is positive                1058                2698"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkGsFbfiWQuR"
      },
      "source": [
        "#### SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_8lha9GWQuR",
        "outputId": "07c07d18-be23-41dd-d524-f66fc10e775b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = svc.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>2745</td>\n",
              "      <td>999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>857</td>\n",
              "      <td>2899</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative                2745                 999\n",
              "Is positive                 857                2899"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lWlWacMWQus"
      },
      "source": [
        "#### Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clq5DxlBWQut",
        "outputId": "84917b48-9c6c-4e09-cbd3-7c6e7c5573bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = bayes.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>2818</td>\n",
              "      <td>926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>989</td>\n",
              "      <td>2767</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative                2818                 926\n",
              "Is positive                 989                2767"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOjMPa_NWQuw"
      },
      "source": [
        "### Percentage-based confusion matrices\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El7gYgbTWQuw"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOczxDwKWQux",
        "outputId": "dd6a9516-bf10-4506-b407-60305506ec27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = logreg.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>0.734776</td>\n",
              "      <td>0.265224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>0.232961</td>\n",
              "      <td>0.767039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative            0.734776            0.265224\n",
              "Is positive            0.232961            0.767039"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYt0VY0zWQuy"
      },
      "source": [
        "#### Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ToR9jxRWQu0",
        "outputId": "6ebb48eb-6373-4df1-dfd5-6ca8d8b8eebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = logreg.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>0.734776</td>\n",
              "      <td>0.265224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>0.232961</td>\n",
              "      <td>0.767039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative            0.734776            0.265224\n",
              "Is positive            0.232961            0.767039"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng5GKtS9WQu3"
      },
      "source": [
        "#### Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UpAXbWeWQu3",
        "outputId": "ecf0ac51-0b79-4023-f0a4-a0d5d1acfad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = forest.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>0.741453</td>\n",
              "      <td>0.258547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>0.281683</td>\n",
              "      <td>0.718317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative            0.741453            0.258547\n",
              "Is positive            0.281683            0.718317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihFVnsTqWQvC"
      },
      "source": [
        "#### SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqk4vAgGWQvD",
        "outputId": "a4d61765-d094-41a9-8f16-4e32fb5e70a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = svc.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>0.733173</td>\n",
              "      <td>0.266827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>0.228168</td>\n",
              "      <td>0.771832</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative            0.733173            0.266827\n",
              "Is positive            0.228168            0.771832"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyCvYvMQWQvH"
      },
      "source": [
        "#### Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH14zuEmWQvI",
        "outputId": "ff0b9ecc-2d7b-4a17-d9cf-71acc00dcf9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = bayes.predict(X_test)\n",
        "matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "label_names = pd.Series(['negative', 'positive'])\n",
        "pd.DataFrame(matrix,\n",
        "     columns='Predicted ' + label_names,\n",
        "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted negative</th>\n",
              "      <th>Predicted positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Is negative</th>\n",
              "      <td>0.752671</td>\n",
              "      <td>0.247329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Is positive</th>\n",
              "      <td>0.263312</td>\n",
              "      <td>0.736688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Predicted negative  Predicted positive\n",
              "Is negative            0.752671            0.247329\n",
              "Is positive            0.263312            0.736688"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsCOoEMxWQvK"
      },
      "source": [
        "## Review\n",
        "\n",
        "- Step 1: use a **vectorizer** to convert the tweets into numbers a computer could understand.\n",
        "- Step 2: Training step to **build** the models \n",
        "- Step 3: split the dataset into **train** and **test** dataset\n",
        "- Step 4: Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yylPihUmWQvL"
      },
      "source": [
        "## Discussion [3]\n",
        "\n",
        "* Which models performed the best? Explain the big differences between them!\n",
        "* Do you think it's more important to be sensitive to negativity or positivity? Do we want more positive things incorrectly marked as negative, or more negative things marked as positive?\n",
        "* They all had very different training times. Which ones offer the best combination of performance?\n",
        "* What's good accuracy? Do you think 75% is good enough?\n",
        "* If there are 2 classifiers and both of them are 75% accurate, which is the best?"
      ]
    }
  ]
}